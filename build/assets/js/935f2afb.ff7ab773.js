"use strict";(self.webpackChunkbuildflow_docs=self.webpackChunkbuildflow_docs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"mainSidebar":[{"type":"link","label":"BuildFlow","href":"/docs/","docId":"intro"},{"type":"link","label":"What is BuildFlow?","href":"/docs/overview","docId":"overview"},{"type":"link","label":"FAQ","href":"/docs/faq","docId":"faq"},{"type":"html","value":"<hr>Programming Guide","className":"sidebar-title"},{"type":"link","label":"Install","href":"/docs/install","docId":"install"},{"type":"link","label":"Key Concepts","href":"/docs/key-concepts","docId":"key-concepts"},{"type":"category","label":"User Guides","items":[{"type":"category","label":"Flows","items":[{"type":"link","label":"Flow Options","href":"/docs/user-guides/flows/flow-options","docId":"user-guides/flows/flow-options"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/flows/overview"},{"type":"category","label":"Processors","items":[{"type":"link","label":"Stateful Processors","href":"/docs/user-guides/processors/stateful-processors","docId":"user-guides/processors/stateful-processors"},{"type":"link","label":"Async Processors","href":"/docs/user-guides/processors/async-processors","docId":"user-guides/processors/async-processors"},{"type":"link","label":"Custom Types","href":"/docs/user-guides/processors/custom-types","docId":"user-guides/processors/custom-types"},{"type":"link","label":"Autoscaling Options","href":"/docs/user-guides/processors/auto-scaling-options","docId":"user-guides/processors/auto-scaling-options"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/processors/overview"},{"type":"category","label":"Pipelines","items":[{"type":"link","label":"Pipeline Options","href":"/docs/user-guides/pipelines/pipeline-options","docId":"user-guides/pipelines/pipeline-options"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/pipelines/overview"},{"type":"category","label":"Collectors","items":[{"type":"link","label":"Collector Options","href":"/docs/user-guides/collectors/collector-options","docId":"user-guides/collectors/collector-options"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/collectors/overview"},{"type":"category","label":"Endpoints","items":[{"type":"link","label":"Endpoint Options","href":"/docs/user-guides/endpoints/endpoint-options","docId":"user-guides/endpoints/endpoint-options"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/endpoints/overview"},{"type":"category","label":"Primitives","items":[{"type":"link","label":"Portable","href":"/docs/user-guides/primitives/portable","docId":"user-guides/primitives/portable"},{"type":"link","label":"Custom Primitives","href":"/docs/user-guides/primitives/custom-primitives","docId":"user-guides/primitives/custom-primitives"}],"collapsed":true,"collapsible":true,"href":"/docs/user-guides/primitives/overview"}],"collapsed":true,"collapsible":true,"href":"/docs/category/user-guides"},{"type":"link","label":"Examples","href":"/docs/examples","docId":"examples"},{"type":"html","value":"<hr>Walkthroughs","className":"sidebar-title"},{"type":"link","label":"Real-Time Image Classification","href":"/docs/walkthroughs/realtime-image-classification","docId":"walkthroughs/realtime-image-classification"},{"type":"html","value":"<hr>Reference","className":"sidebar-title"},{"type":"category","label":"Primitives","items":[{"type":"category","label":"Amazon Web Services","items":[{"type":"link","label":"AWS S3 Bucket","href":"/docs/reference/primitives/aws/s3","docId":"reference/primitives/aws/s3"},{"type":"link","label":"AWS SQS","href":"/docs/reference/primitives/aws/sqs","docId":"reference/primitives/aws/sqs"},{"type":"link","label":"S3 File Change Stream","href":"/docs/reference/primitives/aws/s3_file_change_stream","docId":"reference/primitives/aws/s3_file_change_stream"}],"collapsed":true,"collapsible":true,"href":"/docs/category/amazon-web-services"},{"type":"category","label":"Google Cloud Platform","items":[{"type":"link","label":"Google Cloud BigQuery","href":"/docs/reference/primitives/gcp/gcp_bigquery","docId":"reference/primitives/gcp/gcp_bigquery"},{"type":"link","label":"Google Cloud Pub/Sub","href":"/docs/reference/primitives/gcp/gcp_pubsub","docId":"reference/primitives/gcp/gcp_pubsub"},{"type":"link","label":"Google Cloud Storage","href":"/docs/reference/primitives/gcp/gcp_storage","docId":"reference/primitives/gcp/gcp_storage"},{"type":"link","label":"GCS File Change Stream","href":"/docs/reference/primitives/gcp/gcs_file_change_stream","docId":"reference/primitives/gcp/gcs_file_change_stream"}],"collapsed":true,"collapsible":true,"href":"/docs/category/google-cloud-platform"},{"type":"category","label":"Local","items":[{"type":"link","label":"File","href":"/docs/reference/primitives/local/file","docId":"reference/primitives/local/file"},{"type":"link","label":"File Change Stream","href":"/docs/reference/primitives/local/file_change_stream","docId":"reference/primitives/local/file_change_stream"},{"type":"link","label":"Pulse","href":"/docs/reference/primitives/local/pulse","docId":"reference/primitives/local/pulse"}],"collapsed":true,"collapsible":true,"href":"/docs/category/local"},{"type":"category","label":"Portable","items":[{"type":"link","label":"Queue","href":"/docs/reference/primitives/portable/queue","docId":"reference/primitives/portable/queue"},{"type":"link","label":"Analysis Table","href":"/docs/reference/primitives/portable/analysis_table","docId":"reference/primitives/portable/analysis_table"}],"collapsed":true,"collapsible":true,"href":"/docs/category/portable"},{"type":"link","label":"Snowflake Table","href":"/docs/reference/primitives/snowflake","docId":"reference/primitives/snowflake"},{"type":"link","label":"DuckDB","href":"/docs/reference/primitives/duckdb","docId":"reference/primitives/duckdb"}],"collapsed":true,"collapsible":true,"href":"/docs/category/primitives"},{"type":"category","label":"API","items":[{"type":"link","label":"Primitive","href":"/docs/reference/api/primitive","docId":"reference/api/primitive"},{"type":"link","label":"Provider","href":"/docs/reference/api/provider","docId":"reference/api/provider"},{"type":"link","label":"Strategy","href":"/docs/reference/api/strategy","docId":"reference/api/strategy"}],"collapsed":true,"collapsible":true,"href":"/docs/category/api"},{"type":"category","label":"CLI","items":[{"type":"link","label":"Run","href":"/docs/reference/cli/run","docId":"reference/cli/run"},{"type":"link","label":"Apply","href":"/docs/reference/cli/apply","docId":"reference/cli/apply"},{"type":"link","label":"Plan","href":"/docs/reference/cli/plan","docId":"reference/cli/plan"},{"type":"link","label":"Destroy","href":"/docs/reference/cli/destroy","docId":"reference/cli/destroy"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<hr>Features","className":"sidebar-title"},{"type":"link","label":"Dynamic Autoscaling","href":"/docs/features/autoscaling","docId":"features/autoscaling"},{"type":"link","label":"Parallelism & Concurrency","href":"/docs/features/parallelism","docId":"features/parallelism"},{"type":"link","label":"Infrastructure from Code","href":"/docs/features/infrastructure-from-code","docId":"features/infrastructure-from-code"},{"type":"html","value":"<hr>Developers","className":"sidebar-title"},{"type":"link","label":"Contribute","href":"/docs/developers/contribute","docId":"developers/contribute"}]},"docs":{"developers/contribute":{"id":"developers/contribute","title":"Contribute","description":"We welcome any and all types of contribution! Whether you want to report a bug, request a feature, or submit a pull request, we are always grateful for help.","sidebar":"mainSidebar"},"examples":{"id":"examples","title":"Examples","description":"Below are some quick examples of using BuildFlow. If you are just getting started with BuildFlow we recommend starting with our walkthroughs:","sidebar":"mainSidebar"},"faq":{"id":"faq","title":"FAQ","description":"Can BuildFlow really scale to handle any load?","sidebar":"mainSidebar"},"features/autoscaling":{"id":"features/autoscaling","title":"Dynamic Autoscaling","description":"Buildflow provides horizontal autoscaling out of the box. This allows your Processors to scale up to fit any workload, traffic spikes, or network disruptions without any intervention from an engineer. It will also scale down your application during low traffic periods to help keep your system cost effective.","sidebar":"mainSidebar"},"features/infrastructure-from-code":{"id":"features/infrastructure-from-code","title":"Infrastructure from Code","description":"BuildFlow helps eliminate operational work by including an (optional) resource creation / management module. For most use cases, this can eliminate the need for a separate deployment tool like Terraform or from visit the cloud console.","sidebar":"mainSidebar"},"features/parallelism":{"id":"features/parallelism","title":"Parallelism & Concurrency","description":"BuildFlows runtime is completely asynchronous and built on top of Ray. While BuildFlow will ensure you are getting the most possible parallelism with your IO operations you can easily add more parallelism to your application processing logic.","sidebar":"mainSidebar"},"install":{"id":"install","title":"Install","description":"If you are just getting started with BuildFlow we recommend starting with our walkthroughs:","sidebar":"mainSidebar"},"intro":{"id":"intro","title":"BuildFlow","description":"Build your entire system in minutes using Python","sidebar":"mainSidebar"},"key-concepts":{"id":"key-concepts","title":"Key Concepts","description":"Before getting started with BuildFlow, it\'s important to understand the core concepts and terminology used throughout the documentation.","sidebar":"mainSidebar"},"overview":{"id":"overview","title":"What is BuildFlow?","description":"BuildFlow, is an open source framework for building large scale systems using Python. All you need to do is describe where your input is coming from and where your output should be written, and BuildFlow handles the rest. No configuration outside of the code is required.","sidebar":"mainSidebar"},"reference/api/credentials":{"id":"reference/api/credentials","title":"Credentials","description":"GCP Credentials"},"reference/api/primitive":{"id":"reference/api/primitive","title":"Primitive","description":"GCP Primitive","sidebar":"mainSidebar"},"reference/api/provider":{"id":"reference/api/provider","title":"Provider","description":"Source Provider","sidebar":"mainSidebar"},"reference/api/strategy":{"id":"reference/api/strategy","title":"Strategy","description":"Sink Strategy","sidebar":"mainSidebar"},"reference/cli/apply":{"id":"reference/cli/apply","title":"Apply","description":"The plan command will create / update all resources that are used by the current BuildFlow Node.","sidebar":"mainSidebar"},"reference/cli/destroy":{"id":"reference/cli/destroy","title":"Destroy","description":"The destroy command will delete all resources that are used by the current BuildFlow Node.","sidebar":"mainSidebar"},"reference/cli/plan":{"id":"reference/cli/plan","title":"Plan","description":"The plan command will output all resources that need to be created / destroyed by the current BuildFlow Node.","sidebar":"mainSidebar"},"reference/cli/run":{"id":"reference/cli/run","title":"Run","description":"The plan command will run the current BuildFlow Node.","sidebar":"mainSidebar"},"reference/primitives/aws/s3":{"id":"reference/primitives/aws/s3","title":"AWS S3 Bucket","description":"S3Bucket is a sink primitive that can be used to write various files to an S3 bucket.  The sink primitive takes in a file path and will create one unique file per replica. To create a S3Bucket provide:","sidebar":"mainSidebar"},"reference/primitives/aws/s3_file_change_stream":{"id":"reference/primitives/aws/s3_file_change_stream","title":"S3 File Change Stream","description":"S3FileChangeStream is a source primitive that can be used to subscribe to file changes on a given S3 bucket. To create a S3FileChangeStream provide:","sidebar":"mainSidebar"},"reference/primitives/aws/sqs":{"id":"reference/primitives/aws/sqs","title":"AWS SQS","description":"SQSQueue is a sink and source primitive that can be used to read and write messages to an SQS queue. To create a SQSQueue provide:","sidebar":"mainSidebar"},"reference/primitives/duckdb":{"id":"reference/primitives/duckdb","title":"DuckDB","description":"DuckDB is a sink that can be use to write data to a DuckDB table. To create a DuckDB simply provide:","sidebar":"mainSidebar"},"reference/primitives/gcp/gcp_bigquery":{"id":"reference/primitives/gcp/gcp_bigquery","title":"Google Cloud BigQuery","description":"BigQueryTable","sidebar":"mainSidebar"},"reference/primitives/gcp/gcp_pubsub":{"id":"reference/primitives/gcp/gcp_pubsub","title":"Google Cloud Pub/Sub","description":"GCP Pub/Sub Topic","sidebar":"mainSidebar"},"reference/primitives/gcp/gcp_storage":{"id":"reference/primitives/gcp/gcp_storage","title":"Google Cloud Storage","description":"GCSBucket is a sink primitive that can be used to write various files to a GCS bucket.  The sink primitive takes in a file path and will create one unique file per replica. To create a GCSBucket provide:","sidebar":"mainSidebar"},"reference/primitives/gcp/gcs_file_change_stream":{"id":"reference/primitives/gcp/gcs_file_change_stream","title":"GCS File Change Stream","description":"GCSFileChangeStream is a source primitive that can be used to subscribe to file changes on a given GCS bucket. To create a GCSFileChangeStream provide:","sidebar":"mainSidebar"},"reference/primitives/local/file":{"id":"reference/primitives/local/file","title":"File","description":"File is a sink primitive that can be used to write data to a file. The sink primitive takes in a file path and will create one unique file per replica. To create a File provide the","sidebar":"mainSidebar"},"reference/primitives/local/file_change_stream":{"id":"reference/primitives/local/file_change_stream","title":"File Change Stream","description":"LocalFileChangeStream is a source primitive that can be used to listen to to file change events for a file path. To create a LocalFileChangeStream provide the","sidebar":"mainSidebar"},"reference/primitives/local/pulse":{"id":"reference/primitives/local/pulse","title":"Pulse","description":"Pulse is a source primitive that can be used to periodically send data to your pipeline. This can be useful for testing or for creating a periodic job.","sidebar":"mainSidebar"},"reference/primitives/portable/analysis_table":{"id":"reference/primitives/portable/analysis_table","title":"Analysis Table","description":"AnalyaisTable is a sink portable primitive type that can be used to write data to an analysis table.","sidebar":"mainSidebar"},"reference/primitives/portable/queue":{"id":"reference/primitives/portable/queue","title":"Queue","description":"Queue is a sink and source portable primitive type that can be used to write and read data from a cloud agnostic queue.","sidebar":"mainSidebar"},"reference/primitives/snowflake":{"id":"reference/primitives/snowflake","title":"Snowflake Table","description":"SnowflakeTable is a sink that can be use to write data to a Snowflake table. To create a SnowflakeTable simply provide:","sidebar":"mainSidebar"},"user-guides/collectors/collector-options":{"id":"user-guides/collectors/collector-options","title":"Collector Options","description":"Collectors can be individually configured for different resource requirements:","sidebar":"mainSidebar"},"user-guides/collectors/overview":{"id":"user-guides/collectors/overview","title":"Collectors","description":"The Collector is the pattern provided by BuildFlow for creating an HTTP endpoint that dumps to a give sink. It contains all of the user\'s processing logic between an HTTP request and a sink.","sidebar":"mainSidebar"},"user-guides/endpoints/endpoint-options":{"id":"user-guides/endpoints/endpoint-options","title":"Endpoint Options","description":"Endpoints can be individually configured for different resource requirements:","sidebar":"mainSidebar"},"user-guides/endpoints/overview":{"id":"user-guides/endpoints/overview","title":"Collectors","description":"The Endpoint is the pattern provided by BuildFlow for creating an HTTP endpoint that processes data and returns a response to the user.","sidebar":"mainSidebar"},"user-guides/flows/flow-options":{"id":"user-guides/flows/flow-options","title":"Flow Options","description":"The Flow object take one FlowOptions object for configuring the flow. In the FlowOptions object you can specify any configuration that you want to be applied to all processors in your flow. This include options for configuring the infrastructure and the runtime.","sidebar":"mainSidebar"},"user-guides/flows/overview":{"id":"user-guides/flows/overview","title":"Flows","description":"A Flow is the entity that is run by BuildFlow, and is the container for any processors you would like to run together.","sidebar":"mainSidebar"},"user-guides/pipelines/overview":{"id":"user-guides/pipelines/overview","title":"Pipelines","description":"The Pipeline is the pattern provided by BuildFlow for creating a real-time pipeline. It contains all of the user\'s processing logic between a source and a sink.","sidebar":"mainSidebar"},"user-guides/pipelines/pipeline-options":{"id":"user-guides/pipelines/pipeline-options","title":"Pipeline Options","description":"Pipelines can be individually configured for different resource requirements:","sidebar":"mainSidebar"},"user-guides/primitives/custom-primitives":{"id":"user-guides/primitives/custom-primitives","title":"Custom Primitives","description":"Implement the Primitive Interface","sidebar":"mainSidebar"},"user-guides/primitives/overview":{"id":"user-guides/primitives/overview","title":"Primitives","description":"A full list of provided primitives can be found here","sidebar":"mainSidebar"},"user-guides/primitives/portable":{"id":"user-guides/primitives/portable","title":"Portable","description":"Portable primitives are special primitives that can be used across different cloud providers. You can for example say I want to use a Queue, and based on what cloud you are deploying to we will pick the appropriate resources to create.","sidebar":"mainSidebar"},"user-guides/primitives/resource-management":{"id":"user-guides/primitives/resource-management","title":"Resource Management","description":"When you define the source and sink for you processor not only are you defining the input and output. With BuildFlow you are also defining resources that can be created and destroyed as part of your Flow."},"user-guides/processors/async-processors":{"id":"user-guides/processors/async-processors","title":"Async Processors","description":"TL:DR; If you are using any libraries that require you to use await. You should make your pipeline async.","sidebar":"mainSidebar"},"user-guides/processors/auto-scaling-options":{"id":"user-guides/processors/auto-scaling-options","title":"Autoscaling Options","description":"These options control how the autoscaler should scale individual processors can be passed when creating a processor of any type. All options are optional and have reasonable defaults. Your options are:","sidebar":"mainSidebar"},"user-guides/processors/custom-types":{"id":"user-guides/processors/custom-types","title":"Custom Types","description":"BuildFlow supports using custom types for both the input and your output of the processor. If you are receiving or writing a JSON payload you can simply use a dataclass to get automatic serialization and deserialization.","sidebar":"mainSidebar"},"user-guides/processors/overview":{"id":"user-guides/processors/overview","title":"Processors","description":"A processor is what we like to call a user defined pattern. It is a pre-defined flow of data through a provided pattern. We offer three different implementations of processors:","sidebar":"mainSidebar"},"user-guides/processors/stateful-processors":{"id":"user-guides/processors/stateful-processors","title":"Stateful Processors","description":"Sometimes you need to keep some kind of state between elements your processor is processing. Such as keeping network connections open or loading a model. This can be accomplished by attaching your process to a class instead of a function.","sidebar":"mainSidebar"},"walkthroughs/realtime-image-classification":{"id":"walkthroughs/realtime-image-classification","title":"Real-Time Image Classification","description":"You can follow the same walkthrough using VS Code and LaunchFlow cloud here.","sidebar":"mainSidebar"},"walkthroughs/setup_buildflow":{"id":"walkthroughs/setup_buildflow","title":"Setup LaunchFlow","description":"Install LaunchFlow"}}}')}}]);