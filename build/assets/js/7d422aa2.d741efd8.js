"use strict";(self.webpackChunkbuildflow_docs=self.webpackChunkbuildflow_docs||[]).push([[9567],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>f});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=p(a),d=o,f=m["".concat(s,".").concat(d)]||m[d]||c[d]||i;return a?n.createElement(f,r(r({ref:t},u),{},{components:a})):n.createElement(f,r({ref:t},u))}));function f(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=a.length,r=new Array(i);r[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:o,r[1]=l;for(var p=2;p<i;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},6522:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var n=a(7462),o=(a(7294),a(3905));const i={},r="Snowflake Table",l={unversionedId:"reference/primitives/snowflake",id:"reference/primitives/snowflake",title:"Snowflake Table",description:"SnowflakeTable is a sink that can be use to write data to a Snowflake table. To create a SnowflakeTable simply provide:",source:"@site/docs/reference/primitives/snowflake.md",sourceDirName:"reference/primitives",slug:"/reference/primitives/snowflake",permalink:"/docs/reference/primitives/snowflake",draft:!1,editUrl:"https://github.com/launchflow/buildflow-docs/tree/main/docs/reference/primitives/snowflake.md",tags:[],version:"current",frontMatter:{},sidebar:"mainSidebar",previous:{title:"Analysis Table",permalink:"/docs/reference/primitives/portable/analysis_table"},next:{title:"DuckDB",permalink:"/docs/reference/primitives/duckdb"}},s={},p=[{value:"Types",id:"types",level:2},{value:"Resource Creation",id:"resource-creation",level:2},{value:"Configuration Options",id:"configuration-options",level:2}],u={toc:p},m="wrapper";function c(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"snowflake-table"},"Snowflake Table"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"SnowflakeTable")," is a ",(0,o.kt)("strong",{parentName:"p"},"sink")," that can be use to write data to a Snowflake table. To create a ",(0,o.kt)("inlineCode",{parentName:"p"},"SnowflakeTable")," simply provide:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"table")," ",(0,o.kt)("strong",{parentName:"li"},"required"),": The name of the snowflake table"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"database")," ",(0,o.kt)("strong",{parentName:"li"},"required"),": The name of the database the table exists in"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"schema")," ",(0,o.kt)("strong",{parentName:"li"},"required"),": The name of the schema the table exists in"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"bucket")," ",(0,o.kt)("strong",{parentName:"li"},"*required"),": A ",(0,o.kt)("a",{parentName:"li",href:"aws/s3"},"S3Bucket"),"  that the data will be staged in before writing to Snowflake."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"snow_pipe"),": The name of the Snowflake pipe to use to load the data. If you are using BuildFlow to managed your resources you can leave this out and one will be created for you when you run ",(0,o.kt)("inlineCode",{parentName:"li"},"buildflow apply main:app"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"snowflake_stage"),": The name of the Snowflake stage to use to load the data. If you are using BuildFlow to managed your resources you can leave this out and one will be created for you when you run ",(0,o.kt)("inlineCode",{parentName:"li"},"buildflow apply main:app"),".")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Support for GCS buckets is ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/launchflow/buildflow/issues/250"},"coming soon"),".")),(0,o.kt)("p",null,"Snowflake authentication:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"account"),": The name of the Snowflake account to use"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"user"),": The name of the Snowflake user to use to authenticate as "),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"private_key"),": The private key to use for authentication")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from buildflow.io.snowflake import SnowflakeTable\nfrom buildflow.io.aws import S3Bucket\n\n@app.pipeline(source=...,\n    sink=SnowflakeTable(\n        table="table",\n        database="database",\n        schema="schema",\n        bucket=S3Bucket(bucket_name="bucket").options(managed=True),\n        user="...",\n        private_key="..."))\n    ...\n')),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"Utilities exist for reading in a private key file ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/launchflow/buildflow/blob/main/buildflow/io/snowflake/utils.py"},"here"),".")),(0,o.kt)("h2",{id:"types"},"Types"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"SnowflakeTable")," sink expects an object that can be serialized in to a JSON object. You can return a ",(0,o.kt)("inlineCode",{parentName:"p"},"dataclass")," and we will automatically serialize it for you, or you can return a dictionary containing JSON serializable objects."),(0,o.kt)("p",null,"If you would like to return a custom type that is not JSON serializable you can implement the ",(0,o.kt)("inlineCode",{parentName:"p"},"to_json")," method on your class and we will use that to serialize your object."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'class CustomType:\n    def __init__(self, b: int):\n        self.b = str\n\n    def to_json(self):\n        return {"b": self.b}\n\n@app.pipeline(source=..., sink=SnowflakeTable(...))\nasync def my_processor(elem: int) -> CustomType:\n    return CustomType(b=elem + 1)\n')),(0,o.kt)("h2",{id:"resource-creation"},"Resource Creation"),(0,o.kt)("p",null,"If you are using BuildFlow's built in resource creation/management you can use the ",(0,o.kt)("inlineCode",{parentName:"p"},"SnowflakeTable")," primitive to create a all required resources for you. The following resources will be created:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Snowflake Table"),": A snowflake table with a table schema matching your output type"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Snowflake Database"),": A snowflake database to hold the table (only if ",(0,o.kt)("inlineCode",{parentName:"li"},"database_managed")," option is True)"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Snowflake Schema"),": A snowflake schema to hold the table (only if ",(0,o.kt)("inlineCode",{parentName:"li"},"schema_managed")," option is True)"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"S3 Bucket"),": If the ",(0,o.kt)("inlineCode",{parentName:"li"},"managed")," option on the provided bucket is set to True"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Snowflake Stage"),": A snowflake stage to load the data from the bucket if the ",(0,o.kt)("inlineCode",{parentName:"li"},"snowflake_stage")," option is not provided"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Snowflake Pipe"),": A snowflake pipe to load the data from the stage if the ",(0,o.kt)("inlineCode",{parentName:"li"},"snowflake_pipe")," option is not provided")),(0,o.kt)("h2",{id:"configuration-options"},"Configuration Options"),(0,o.kt)("p",null,"You can provide the following options to control resource management of the BigQuery table:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"managed"),": Whether or not the topic is managed by BuildFlow. Defaults to ",(0,o.kt)("inlineCode",{parentName:"li"},"False"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"database_managed"),": Whether or not the database should be included in resource management / creation. Defaults to ",(0,o.kt)("inlineCode",{parentName:"li"},"True"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"schema_managed"),": Whether or not the database should be included in resource management / creation. Defaults to ",(0,o.kt)("inlineCode",{parentName:"li"},"True"),".")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"SnowflakeTable(...).options(managed=True, database_managed=True, schema_managed=True)\n")))}c.isMDXComponent=!0}}]);