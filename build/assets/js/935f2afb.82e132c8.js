"use strict";(self.webpackChunkbuildflow_docs=self.webpackChunkbuildflow_docs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"mainSidebar":[{"type":"link","label":"BuildFlow","href":"/docs/","docId":"intro"},{"type":"category","label":"What is BuildFlow?","items":[{"type":"link","label":"Overview","href":"/docs/what_is_buildflow/overview","docId":"what_is_buildflow/overview"},{"type":"link","label":"Concepts","href":"/docs/what_is_buildflow/concepts","docId":"what_is_buildflow/concepts"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<hr>Get Started","className":"sidebar-title"},{"type":"link","label":"Install","href":"/docs/install","docId":"install"},{"type":"link","label":"Quickstart","href":"/docs/quickstart","docId":"quickstart"},{"type":"html","value":"<hr>API References","className":"sidebar-title"},{"type":"link","label":"Processor API","href":"/docs/apis/processor","docId":"apis/processor"},{"type":"link","label":"Node API","href":"/docs/apis/node","docId":"apis/node"},{"type":"category","label":"IO Providers","items":[{"type":"link","label":"Provider API","href":"/docs/apis/providers/base","docId":"apis/providers/base"},{"type":"link","label":"BigQueryTable","href":"/docs/apis/providers/bigquery_table","docId":"apis/providers/bigquery_table"},{"type":"link","label":"GCPPubSubSubscription","href":"/docs/apis/providers/gcp_pubsub_subscription","docId":"apis/providers/gcp_pubsub_subscription"}],"collapsed":true,"collapsible":true},{"type":"html","value":"<hr>Walkthroughs","className":"sidebar-title"},{"type":"link","label":"GCP Pub/Sub Streaming","href":"/docs/walkthroughs/pubsub_streaming","docId":"walkthroughs/pubsub_streaming"},{"type":"link","label":"Local GCP Pub/Sub to Parquet","href":"/docs/walkthroughs/local_pubsub_streaming","docId":"walkthroughs/local_pubsub_streaming"},{"type":"link","label":"GCS CSV to GCP BigQuery Streaming","href":"/docs/walkthroughs/csv_bigquery_streaming","docId":"walkthroughs/csv_bigquery_streaming"},{"type":"link","label":"AWS SQS Streaming","href":"/docs/walkthroughs/aws_sqs_streaming","docId":"walkthroughs/aws_sqs_streaming"},{"type":"html","value":"<hr>Architecture","className":"sidebar-title"},{"type":"link","label":"Runtime","href":"/docs/architecture/runtime","docId":"architecture/runtime"},{"type":"link","label":"Infrastructure","href":"/docs/architecture/infrastructure","docId":"architecture/infrastructure"}]},"docs":{"apis/deployment-grid":{"id":"apis/deployment-grid","title":"deployment-grid","description":""},"apis/node":{"id":"apis/node","title":"Node API","description":"The Node object is the container for your application.","sidebar":"mainSidebar"},"apis/processor":{"id":"apis/processor","title":"Processor API","description":"The Processor API is the primary abstraction provided by BuildFlow. It contains all of the user\'s processing logic between the IO Connectors. Processors come in two different flavors: streaming and batch. The main difference between the two is that in batch mode you operate on a Ray DataSet, and in streaming mode you operate on individual elements.","sidebar":"mainSidebar"},"apis/providers/base":{"id":"apis/providers/base","title":"Provider API","description":"IO Providers provide effecient I/O between popular cloud services & storage systems.","sidebar":"mainSidebar"},"apis/providers/bigquery_table":{"id":"apis/providers/bigquery_table","title":"BigQueryTable","description":"IO Providers provide effecient I/O between popular cloud services & storage systems.","sidebar":"mainSidebar"},"apis/providers/gcp_pubsub_subscription":{"id":"apis/providers/gcp_pubsub_subscription","title":"GCPPubSubSubscription","description":"IO Providers provide effecient I/O between popular cloud services & storage systems.","sidebar":"mainSidebar"},"architecture/infrastructure":{"id":"architecture/infrastructure","title":"Infrastructure","description":"A Streaming Processor is any processor that consumes an un-bounded stream of data, such as a Google Cloud Pub/Sub feed.","sidebar":"mainSidebar"},"architecture/overview":{"id":"architecture/overview","title":"Overview","description":"The Processor API is the primary abstraction provided by BuildFlow. It contains all of the user\'s processing logic between the IO Connectors. Processors come in two different flavors: streaming and batch. The main difference between the two is that in batch mode you operate on a Ray DataSet, and in streaming mode you operate on individual elements."},"architecture/runtime":{"id":"architecture/runtime","title":"Runtime","description":"A Batch Processor is any processor the consumes a bounded set of data, such as a BigQuery table or SQL query.","sidebar":"mainSidebar"},"autoscaling":{"id":"autoscaling","title":"Dynamic Autoscaling","description":"Buildflow provides horizontal autoscaling out of the box. This allows your Processors to scale up to fit any workload, traffic spikes, or network disruptions without any intervention from an engineer. It will also scale down your application during low traffic periods to help keep your system cost effective."},"deployment-grid":{"id":"deployment-grid","title":"Deployment Grid","description":"The DeploymentGrid object is responsible for deploying Nodes."},"install":{"id":"install","title":"Install","description":"BuildFlow, is an open source framework for building large scale systems using Python. All you need to do is describe where your input is coming from and where your output should be written, and BuildFlow handles the rest. No configuration outside of the code is required.","sidebar":"mainSidebar"},"intro":{"id":"intro","title":"BuildFlow","description":"Build your entire system in minutes using Python","sidebar":"mainSidebar"},"io-providers/aws_sqs":{"id":"io-providers/aws_sqs","title":"AQS SWS","description":"AWS SQS support is currenty in prototype mode, and only SQS as a source is supported."},"io-providers/gcp_bigquery":{"id":"io-providers/gcp_bigquery","title":"Google Cloud BigQuery","description":"BigQuery refers to Google\'s BigQuery data warehouse. It is a batch source connector, and can be used in both streaming and batch runtimes as a sink connector."},"io-providers/gcp_pubsub":{"id":"io-providers/gcp_pubsub","title":"Google Cloud PubSub","description":"PubSub refers to Google\'s Pub/Sub service. It is a streaming source connector."},"io-providers/gcs_notifications":{"id":"io-providers/gcs_notifications","title":"Google Cloud Storage Notifications","description":"The GCS Notification source subscribes to changes to a Google Cloud Storage bucket. This source is a streaming source. You provide the source with the GCP project and the GCS bucket you would like to listen to and BuildFlow will configure your application to listen to changes. It does this by setting up a Pub/Sub topic and subscriber that will listen to changes on the bucket. If you have already configured a topic and subscriber for this you can also manually pass those."},"io-providers/overview":{"id":"io-providers/overview","title":"Overview","description":"IO Connectors provide effecient I/O between popular cloud services & storage systems."},"processors/batch":{"id":"processors/batch","title":"Batch","description":"A Batch Processor is any processor the consumes a bounded set of data, such as a BigQuery table or SQL query."},"processors/streaming":{"id":"processors/streaming","title":"Streaming","description":"A Streaming Processor is any processor that consumes an un-bounded stream of data, such as a Google Cloud Pub/Sub feed."},"quickstart":{"id":"quickstart","title":"Quickstart","description":"BuildFlow, is an open source framework for building large scale systems using Python. All you need to do is describe where your input is coming from and where your output should be written, and BuildFlow handles the rest. No configuration outside of the code is required.","sidebar":"mainSidebar"},"resource-creation":{"id":"resource-creation","title":"Resource Creation","description":"BuildFlow helps eliminate operational work by including an (optional) resource creation / management module. For most use cases, this can eliminate the need for a separate deployment tool like Terraform."},"schema-validation":{"id":"schema-validation","title":"Schema Validation","description":"BuildFlow uses python type hits and dataclasses to ensure that that output of your Processor matches the schema defintion of your sink (for supported sinks). This can be useful for catching schema mis-match errors before you launch your application."},"walkthroughs/aws_sqs_streaming":{"id":"walkthroughs/aws_sqs_streaming","title":"AWS SQS Streaming","description":"AWS SQS support is currenty in prototype mode, and only SQS as a source is supported.","sidebar":"mainSidebar"},"walkthroughs/csv_bigquery_streaming":{"id":"walkthroughs/csv_bigquery_streaming","title":"GCS CSV to GCP BigQuery Streaming","description":"In this walkthrough we will run a BuildFlow application that listens for CSV file uploads to a Google Cloud Storage bucket. When an upload occurs the BuildFlow application will read the corresponding file, perform any necessary transformations on it, and upload the results to BigQuery. You can find all the code for this walk through here.","sidebar":"mainSidebar"},"walkthroughs/local_pubsub_streaming":{"id":"walkthroughs/local_pubsub_streaming","title":"Local GCP Pub/Sub to Parquet","description":"In this walkthrough we will run a BuildFlow application that reads from a local Pub/Sub topic and writes the data to a local parquet file. You can find all the code for this walk through here.","sidebar":"mainSidebar"},"walkthroughs/pubsub_streaming":{"id":"walkthroughs/pubsub_streaming","title":"GCP Pub/Sub Streaming","description":"In this walkthrough we will run a BuildFlow application that reads from a Pub/Sub topic containing publically available taxi data and write the data to BigQuery. You can find all the code for this walk through here.","sidebar":"mainSidebar"},"walkthroughs/setup_buildflow":{"id":"walkthroughs/setup_buildflow","title":"Setup LaunchFlow","description":"Install LaunchFlow"},"what_is_buildflow":{"id":"what_is_buildflow","title":"What is BuildFlow?","description":""},"what_is_buildflow/concepts":{"id":"what_is_buildflow/concepts","title":"Concepts","description":"Nodes","sidebar":"mainSidebar"},"what_is_buildflow/overview":{"id":"what_is_buildflow/overview","title":"Overview","description":"BuildFlow, is an open source framework for building large scale systems using Python. All you need to do is describe where your input is coming from and where your output should be written, and BuildFlow handles the rest. No configuration outside of the code is required.","sidebar":"mainSidebar"}}}')}}]);