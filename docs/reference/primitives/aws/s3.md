# AWS S3 Bucket

`S3Bucket` is a sink primitive that can be used to write various files to an S3 bucket. To create a `S3Bucket` provide:

- `bucket_name` **required**: The name of the bucket
- `file_path` **required**: The file path to write to
- `file_format` **required**: The file format to write valid options are: JSON, CSV, and PARQUET
- `aws_region`: The region the bucket exists in


Example usage:

```python
from buildflow.io.aws import S3Bucket

@app.pipeline(source=..., sink=S3Bucket(
    bucket_name="bucket",
    aws_region="us-east-1",
    file_path="path/to/file_in_bucket",
    file_format="PARQUET")
)
```

:::

## Types
The `S3Bucket` sink expects an object that can be serialized in to a JSON object. You can return a `dataclass` and we will automatically serialize it for you, or you can return a dictionary containing JSON serializable objects.

If you would like to return a custom type that is not JSON serializable you can implement the `to_json` method on your class and we will use that to serialize your object.

```python
class CustomType:
    def __init__(self, b: int):
        self.b = str

    def to_json(self):
        return {"b": self.b}

@app.pipeline(source=..., sink=S3Bucket(...))
async def my_processor(elem: int) -> CustomType:
    return CustomType(b=elem + 1)
```

## Resource Creation

If you are using BuildFlow's built in resource creation/management you can use the `S3Bucket` primitive to create a bucket in your AWS account.


## Configuration Options

You can provide the following options to control resource management of the S3 bucket:

- `managed`: Whether or not the topic is managed by BuildFlow. Defaults to `False`.
- `force_destroy`: If true destroy will fail if the bucket contains objects. Defaults to `False`.

```python
primitive = S3Bucket(...).options(managed=True, force_destroy=True)
```
